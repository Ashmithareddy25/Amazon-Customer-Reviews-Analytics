# ğŸ›’ Amazon Customer Reviews Analytics  
## A Complete End-to-End Big Data, NLP, and Machine Learning Pipeline Using Apache Spark

---

## ğŸ“˜ Project Overview

This project implements a complete big data analytics pipeline to process, analyze, and model Amazon customer reviews. Using Apache Spark, PySpark MLlib, and Python, the system ingests raw review data, performs scalable transformations, extracts sentiment and topics from text, predicts ratings and helpfulness, and generates analytical insights. The pipeline also simulates real-time ingestion using file-based streaming and produces structured output files for visualization or further analysis.

---

## ğŸ¯ Key Objectives

- Build an end-to-end scalable data pipeline for Amazon customer reviews  
- Clean, preprocess, and transform raw review data for analytics and machine learning  
- Perform Spark SQL analytics to extract category-wise insights, trends, and patterns  
- Engineer features for NLP and machine learning readiness  
- Train machine learning models for sentiment classification, rating prediction, helpfulness prediction, and topic modeling  
- Generate a Product Worthiness Score combining sentiment, rating, helpfulness, recency, and verified purchase behavior  
- Simulate real-time review ingestion using file-based streaming  
- Produce clean output datasets and results consumable by dashboards  

---

## ğŸ“¦ Dataset Description

The project uses a structured Parquet dataset containing more than **50,000+ Amazon product reviews**.
**Dataset:** [Amazon US Customer Reviews Dataset (Kaggle)](https://www.kaggle.com/datasets/cynthiarempel/amazon-us-customer-reviews-dataset)  
*(Originally part of the AWS Open Data Registry)*

### **Dataset Fields**
- `review_id` â€“ Unique identifier  
- `product_id` â€“ ASIN of product  
- `product_title`  
- `review_body` â€“ Text review  
- `star_rating` â€“ Rating (1â€“5)  
- `review_date`  
- `verified_purchase`  
- `helpful_votes` / `total_votes`  
- `product_category`

---

### **ğŸ—ï¸ Architecture**

```bash
                  Raw Data (Parquet)
                            â”‚
                            â–¼
                Data Cleaning & Preprocessing
                            â”‚
                            â–¼
                 Spark Batch Ingestion (ETL)
                            â”‚
                            â–¼
                  Spark SQL + EDA Analytics
                            â”‚
                            â–¼
                    Feature Engineering
                            â”‚
                            â–¼
               Machine Learning (MLlib + Python)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Logistic Regression â€“ Sentiment             â”‚
        â”‚ Linear Regression â€“ Rating Prediction       â”‚
        â”‚ RandomForest â€“ Helpfulness Prediction       â”‚
        â”‚ LDA Topic Modeling â€“ Theme Extraction       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                 Output (CSV/Parquet predictions)
                            â”‚
                            â–¼
                    Optional Streaming Layer
                            â”‚
                            â–¼
                External Dashboard (Streamlit)
```
---


### **ğŸ“‚ Repository Structure**

```bash

Amazon-Customer-Reviews-Analytics/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Original dataset
â”‚   â”œâ”€â”€ cleaned/              # Cleaned data files
â”‚   â”œâ”€â”€ stream_input/         # Files used for streaming simulation
â”‚   â”œâ”€â”€ output_csv/           # Batch pipeline output
â”‚   â””â”€â”€ output_parquet/       # Parquet output for downstream use
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingestion.py          # Spark data ingestion pipeline
â”‚   â”œâ”€â”€ data_cleaning.py      # Cleaning and preprocessing
â”‚   â”œâ”€â”€ preprocessing.py      # NLP + feature engineering
â”‚   â”œâ”€â”€ stream_pipeline.py    # File-based streaming logic
â”‚   â””â”€â”€ utils.py              # Helper utilities
â”‚
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ live_review_analyzer.py      # Live review scoring / sentiment
â”‚   â”œâ”€â”€ model_inference.py           # Load models and run inference
â”‚   â”œâ”€â”€ product_demand_predictor.py  # Demand/helpfulness forecast
â”‚   â”œâ”€â”€ rating_regression.py         # Rating prediction model (regression)
â”‚   â”œâ”€â”€ review_forecast.py           # Review volume forecasting
â”‚   â”œâ”€â”€ sentiment_ml.py              # Sentiment classification (ML)
â”‚   â””â”€â”€ topic_modeling.py            # LDA topic modeling
â”‚   â””â”€â”€ __models__/                  # Stored models and vectorizers
â”‚
â”œâ”€â”€ models/                   # Additional trained model assets
â”œâ”€â”€ notebooks/                # EDA and experimentation notebooks
â”œâ”€â”€ reports/                  # PDF documentation and project reports
â”‚
â”œâ”€â”€ dashboard_app.py          # Streamlit dashboard (optional)
â”œâ”€â”€ run.sh                    # End-to-end execution script
â”œâ”€â”€ Makefile                  # Automation commands
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

```

---


## ğŸ”§ Prerequisites

### **Software Requirements**
```bash
Python 3.8+
Apache Spark 3.x
Java 8+
pip / virtualenv
```

### **Python Libraries**
```bash
pyspark
pandas
numpy
scikit-learn
nltk
joblib
```

---

## ğŸ”„ End-to-End Pipeline Details

### **1. Dataset Ingestion**
- Loads Parquet dataset using Spark Structured APIs  
- Reads data into Spark DataFrames for distributed processing  
- Converts and stores intermediate data in efficient columnar Parquet format  

### **2. Data Cleaning**
- Removes duplicates using `review_id`  
- Drops rows missing key fields  
- Normalizes text (lowercasing, removing symbols, trimming whitespace)  
- Converts `verified_purchase` to a binary flag  
- Parses `review_date` into proper date format  

### **3. Feature Engineering**
- Creates `review_length`, `helpfulness_ratio`, `verified_flag`  
- Extracts `year` and `month` from `review_date`  
- Computes sentiment using rule-based polarity functions  
- Performs NLP feature extraction:  
  - Tokenization  
  - Stopwords removal  
  - TF-IDF vectorization  

### **4. Spark SQL Analytics**
- Computes product categoryâ€“level insights  
- Identifies top products by review count, helpfulness, and verified ratios  
- Analyzes rating distribution patterns  
- Extracts monthly sentiment and rating trends  
- Identifies highly helpful reviews  

### **5. Machine Learning Models**

#### **Sentiment Classification (Logistic Regression)**
- Predicts Positive / Neutral / Negative sentiment  
- Uses TF-IDF text vectors + numeric features  

#### **Rating Prediction (Linear Regression)**
- Predicts expected star rating from review text  

#### **Helpfulness Prediction (RandomForestRegressor)**
- Predicts `helpful_votes` using metadata + text features  

#### **Topic Modeling (LDA)**
- Extracts dominant themes from reviews  
- Helps uncover common customer concerns  

#### **Rule-Based Sentiment**
- Keyword-based polarity scoring  
- Used as a simple baseline model  

### **6. Evaluation Metrics**
- Accuracy  
- Precision  
- Recall  
- F1-score  
- Confusion Matrix  
- MSE / RMSE  
- RÂ²  

### **7. Streaming Component**
- Uses file-based streaming simulation  
- Automatically processes new review files placed in `stream_input/`  
- Produces incremental outputs for nearâ€“real-time updates  

---

## ğŸ“Š Main Insights From the Pipeline
- Reviews are heavily skewed toward 4â€“5 star ratings  
- Verified purchases provide more trustworthy and positive ratings  
- Helpful votes follow a skewed long-tail distribution  
- Longer reviews generally receive more helpful votes  
- Seasonal patterns and category-specific behaviors emerge  
- Sentiment correlates strongly with star ratings  
- LDA Topic Modeling highlights themes such as quality, delivery, and price  

---
## ğŸ› ï¸ Execution Setup

### 1. Create a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate       # Mac/Linux
venv\Scripts\activate          # Windows
```

### 2. Install Requirements
```bash
pip install -r requirements.txt
```

### 3. Run Full End-to-End Pipeline
```bash
bash run.sh
```

### 4. Run Individual Components
**Ingestion**
```bash
python scripts/ingestion.py
```
**Cleaning**
```bash
python scripts/data_cleaning.py
```
**Feature Engineering**
```bash
python scripts/preprocessing.py
```

**ML Models**
- **Sentiment Classification â€“ Logistic Regression**
```bash
python ml/sentiment_ml.py
```
- **Linear Regression â€“ Rating Prediction**
```bash
python ml/rating_regression.py
```
- **Helpfulness Prediction â€“ RandomForestRegressor**
```bash
python ml/product_demand_predictor.py
```

- **Topic Modeling â€“ LDA**
```bash
python ml/topic_modeling.py
```

---

### âœ”ï¸ Summary

This project implements a complete end-to-end big data pipeline built on Apache Spark with integrated NLP and machine learning modules. It automates data ingestion, cleaning, preprocessing, feature engineering, analytics, and model training for Amazon reviews at scale. The system produces structured outputs, generates meaningful insights, and supports simulated real-time updates, enabling deeper understanding of customer behavior and product performance.

---

[**VIDEO RECORDING** ](https://drive.google.com/file/d/1wz9NxPkv3Lelz5qNbY1PaGAN-jZmxEpk/view?usp=sharing)

